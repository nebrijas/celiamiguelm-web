{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a9bca1",
   "metadata": {},
   "source": [
    "# Prgramación literaria con Juputer (ad3)\n",
    "## Web Scraping con Python\n",
    "Este programa se encarga de hacer **web scraping** en varias URLs de una misma web. Los resultados son almacenados y clasificados por palabras clave para imprimirlos al final del programa por consola."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c7066",
   "metadata": {},
   "source": [
    "### Librerías utilizadas\n",
    "+ requests: [requests es una librería Python que facilita enormemente el trabajo con peticiones HTTP.](https://j2logo.com/python/python-requests-peticiones-http/)\n",
    "+ bs4: [Beautiful Soup es una librería Python que permite extraer información de contenido en formato HTML o XML.](https://j2logo.com/python/web-scraping-con-python-guia-inicio-beautifulsoup/)\n",
    "+ pandas: [Pandas es una librería de Python especializada en el manejo y análisis de estructuras de datos.](https://aprendeconalf.es/docencia/python/manual/pandas/)\n",
    "+ termcolor: [formato de color ANSII para salida en terminal.](https://pypi.org/project/termcolor/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dd74e",
   "metadata": {},
   "source": [
    "### Módulos utilizados\n",
    "+ time: [El módulo time de la biblioteca estándar de Python proporciona un conjunto de funciones para trabajar con fechas y/o horas.](https://python-para-impacientes.blogspot.com/2017/03/el-modulo-time.html)\n",
    "+ csv: [El módulo csv implementa clases para leer y escribir datos tabulares en formato CSV.](https://docs.python.org/es/3/library/csv.html)\n",
    "+ re: [Este módulo proporciona operaciones de coincidencia de expresiones regulares similares a las encontradas en Perl.](https://docs.python.org/es/3/library/re.html)\n",
    "+ os: [Este módulo provee una manera versátil de usar funcionalidades dependientes del sistema operativo.](https://docs.python.org/es/3.10/library/os.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f5844",
   "metadata": {},
   "source": [
    "### Descripción del programa\n",
    "El primer paso, como en cualquier lenguaje de programación, es importar las librerías que va a necesitar el script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402279ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf96edcb",
   "metadata": {},
   "source": [
    "Se declara la variable **resultados** y se inicializa como un array vacío. En ella se van almacenando los resultados de cada una de las URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb93cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4e4d65",
   "metadata": {},
   "source": [
    "Después, se realiza una petición **HTTP GET** a la URL de la web donde se quiere hacer web scraping. Esta petición devuelve una respuesta que se almacena en una variable llamada `req`. Esta variable es de tipo objeto y contiene tanto atributos como funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"https://resultados.elpais.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4540c3",
   "metadata": {},
   "source": [
    "Para comprobar que la petición se ha realizado con éxito, se utiliza uno de los atributos disponibles en el objeto `req` llamado `status_code`. Si el valor es igual a **200**, la petición se ha realizado con éxito. En caso contrario, se lanza una excepción para avisar cual ha sido la URL que ha fallado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (req.status_code != 200):\n",
    "    raise Exception(\"No se puede hacer Web Scraping en\"+ URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce5946",
   "metadata": {},
   "source": [
    "Una vez se comprueba que la petición ha sido exitosa, se extrae todo el texto HTML de la página web con ayuda de una de las funciones de la librería **bs4**: `BeautifulSoup`. En esta función se le pasan dos parámetros: el texto obtenido de la petición HTTP a la web, y el tipo de texto que tiene que extraer. El resultado se almacena en una variable llamada `soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb1833",
   "metadata": {},
   "source": [
    "Como el objetivo es obtener los titulares de cada URL, tan solo es necesario el texto de las etiqueteas `<h2>`. Para hacer el filtrado, se utiliza una de las funciones que contiene el objeto `soup` llamada `findAll`. De esta manera solo se almacenan en la variable `tags` el texto de los titulares de la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed659b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = soup.findAll(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15504167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d639c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
